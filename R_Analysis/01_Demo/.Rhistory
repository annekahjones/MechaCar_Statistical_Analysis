y_hat1 = as.numeric(pi_hat_logistic > tau)
y_hat1
overall_accuracy_train1 = mean(fraud[train_set] == y_hat1)
overall_accuracy_train1
auc_log_train = calc_auc(fraud[train_set], pi_hat_logistic)
auc_log_train
tau = 0.50
slr_train = glm(fraud ~ gender + age + college + score + amount + declines, family = "binomial", data = cc_fraud, subset = train_set)
slr_train
pi_hat_logistic = predict(slr_train, type="response")
pi_hat_logistic
y_hat1 = as.numeric(pi_hat_logistic > tau)
y_hat1
overall_accuracy_train1 = mean(fraud[train_set] == y_hat1)
overall_accuracy_train1
auc_log_train = calc_auc(fraud[train_set], pi_hat_logistic)
auc_log_train
draw_roc(fraud[train_set], pi_hat_logistic)
draw_roc(fraud[train_set], pi_hat_logistic)
pi_hat_logistic2 = predict(slr_train, type= "response", newdata=cc_fraud[test_set,])
pi_hat_logistic2
y_hat2 = as.numeric(pi_hat_logistic2 > tau)
y_hat2
overall_accuracy_test2 = mean(fraud[test_set] == y_hat2)
overall_accuracy_test2
auc_log_test = calc_auc(fraud[test_set], pi_hat_logistic2)
auc_log_test
draw_roc(fraud[test_set], pi_hat_logistic2)
my_lda = lda(fraud ~ gender + age + college + score + amount + declines, subset=train_set)
my_lda
pi_hat_lda = predict(my_lda)$posterior[,2]
pi_hat_lda
y_hat3 = as.numeric(pi_hat_lda > tau)
y_hat3
overall_accuracy_train3 = mean(fraud[train_set] == y_hat3)
overall_accuracy_train3
auc_lda_train = calc_auc(fraud[train_set], pi_hat_lda)
auc_lda_train
draw_roc(fraud[train_set], pi_hat_lda)
pi_hat_lda2 = predict(my_lda, newdata=cc_fraud[test_set,])$posterior[,2]
pi_hat_lda2
y_hat4 = as.numeric(pi_hat_lda2 > tau)
y_hat4
overall_accuracy_test4 = mean(fraud[test_set] == y_hat4)
overall_accuracy_test4
auc_lda_test = calc_auc(fraud[test_set], pi_hat_lda2)
auc_lda_test
draw_roc(fraud[test_set], pi_hat_lda2)
gm = gam(fraud ~ gender + s(age,4) + college + s(score,4) + s(amount,4) + s(declines,4), subset=train_set, binomial)
pi_hat_gam = predict(gm)
pi_hat_gam
y_hat5 = as.numeric(pi_hat_gam > tau)
y_hat5
overall_accuracy_train5 = mean(fraud[train_set] == y_hat5)
overall_accuracy_train5
auc_gam_train = calc_auc(fraud[train_set], pi_hat_gam)
auc_gam_train
draw_roc(fraud[train_set], pi_hat_gam)
pi_hat_gam2 = predict(gm, newdata=cc_fraud[test_set,])
pi_hat_gam2
y_hat6 = as.numeric(pi_hat_gam2 > tau)
y_hat6
overall_accuracy_test6 = mean(fraud[test_set] == y_hat6)
overall_accuracy_test6
auc_gam_test = calc_auc(fraud[test_set], pi_hat_gam2)
auc_gam_test
draw_roc(fraud[test_set], pi_hat_gam2)
fraud_f = factor(fraud)
tree_class = tree(fraud_f ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_tree = predict(tree_class)[,2]
y_hat7 = as.numeric(pi_hat_tree > tau)
y_hat7
overall_accuracy_train7 = mean(fraud[train_set] == y_hat7)
overall_accuracy_train7
auc_tree_train = calc_auc(fraud[train_set], pi_hat_tree)
auc_tree_train
draw_roc(fraud[train_set], pi_hat_tree)
pi_hat_tree2 = predict(tree_class, newdata=cc_fraud[test_set,])[,2]
y_hat8 = as.numeric(pi_hat_tree2 > tau)
y_hat8
overall_accuracy_test8 = mean(fraud[train_set] == y_hat8)
overall_accuracy_test8
auc_tree_test = calc_auc(fraud[test_set], pi_hat_tree2)
auc_tree_test
draw_roc(fraud[test_set], pi_hat_tree2)
set.seed(4350)
my_forest = randomForest(fraud_f ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_forest = predict(my_forest, type="prob")[,2]
y_hat9 = as.numeric(pi_hat_forest > tau)
y_hat9
overall_accuracy_train9 = mean(fraud[train_set] == y_hat9)
overall_accuracy_train9
auc_forest_train = calc_auc(fraud[train_set], pi_hat_forest)
auc_forest_train
draw_roc(fraud[train_set], pi_hat_forest)
pi_hat_forest2 = predict(my_forest, type="prob", newdata=cc_fraud[test_set,])[,2]
y_hat10 = as.numeric(pi_hat_forest2 > tau)
y_hat10
auc_forest_test = calc_auc(fraud[test_set], pi_hat_forest2)
auc_forest_test
overall_accuracy_test10 = mean(fraud[test_set] == y_hat10)
overall_accuracy_test10
draw_roc(fraud[test_set], pi_hat_forest2)
install.packages("gam")
install.packages("gam")
##### Installing necessary packages #####
install.packages("gam")
library(gam)
library(MASS)
install.packages("tree")
library(tree)
install.packages("randomForest")
library(randomForest)
load("/Users/annekahjones/Downloads/cc_fraud.RData")
attach(cc_fraud)
cc_fraud
# Function for finding AUC
calc_auc <- function(y,ph) {
taus <- seq(0,1,0.001) # thresholds for ph for classifying y as 1
sens <- numeric(length(taus)) # vector to store sensitivity values
fpr <- numeric(length(taus)) # vector to store false positive rate values
for (i in 1:length(taus)) {
sens[i] <- mean(ph[y==1] > taus[i])
fpr[i] <- mean(ph[y==0] > taus[i])
}
sens <- c(1,sens)
fpr <- c(1,fpr)
sum( (sens[-1] + sens[-length(sens)])/2 * (fpr[-length(fpr)] - fpr[-1]) )
}
# Function for drawing an ROC curve
draw_roc <- function(y,ph,clr="red",new=TRUE) {
taus <- seq(0,1,0.001) # thresholds for ph for classifying y as 1
sens <- numeric(length(taus)) # vector to store sensitivity values
fpr <- numeric(length(taus)) # vector to store false positive rate values
for (i in 1:length(taus)) {
sens[i] <- mean(ph[y==1] > taus[i])
fpr[i] <- mean(ph[y==0] > taus[i])
}
sens <- c(1,sens)
fpr <- c(1,fpr)
# if new==TRUE, draw a new plot:
if (new) {
plot(NA,NA,type="n",xlim=c(0,1),ylim=c(0,1),
xlab="False Positive Rate",
ylab="Sensitivity")
abline(h=c(0,1),v=c(0,1),a=0,b=1)
}
lines(fpr,sens,lwd=2,col=clr)
}
summary(age)
summary(score)
summary(amount)
summary(declines)
table(fraud)
table(gender)
table(college)
boxplot(age, main = "Age of credit card users", ylab = "Age (years)")
boxplot(score, main = "Credit score of credit card users", ylab = "Credit score")
boxplot(amount, main = "Average amount of last 5 attempted charges", ylab = "Amount (US Dollars")
boxplot(declines, main = "Number of declines in last 5 attempted charges", ylab = "Number of declines")
boxplot(score ~ fraud, main = "Credit score and fraud detection", ylab = "Credit Score", xlab = "Fraud detected")
hist(age, main = "Age of credit card users")
hist(score, main = "Credit Score of credit card users")
hist(amount, main = "Average amount of last 5 attenpted charges")
hist(declines, main = "Number of declines in last 5 attempted charges")
set.seed(4350)
n = nrow(cc_fraud)
n_train = ceiling(0.5*n)
n_train
n_test = n - n_train
n_test
train_set = sample(n,n_train,replace=FALSE)
train_set
test_set = seq_len(n)[-train_set]
test_set
tau = 0.50
slr_train = glm(fraud ~ gender + age + college + score + amount + declines, family = "binomial", data = cc_fraud, subset = train_set)
slr_train
pi_hat_logistic = predict(slr_train, type="response")
pi_hat_logistic
y_hat1 = as.numeric(pi_hat_logistic > tau)
y_hat1
overall_accuracy_train1 = mean(fraud[train_set] == y_hat1)
overall_accuracy_train1
auc_log_train = calc_auc(fraud[train_set], pi_hat_logistic)
auc_log_train
draw_roc(fraud[train_set], pi_hat_logistic)
pi_hat_logistic2 = predict(slr_train, type= "response", newdata=cc_fraud[test_set,])
pi_hat_logistic2
y_hat2 = as.numeric(pi_hat_logistic2 > tau)
y_hat2
overall_accuracy_test2 = mean(fraud[test_set] == y_hat2)
overall_accuracy_test2
auc_log_test = calc_auc(fraud[test_set], pi_hat_logistic2)
auc_log_test
draw_roc(fraud[test_set], pi_hat_logistic2)
my_lda = lda(fraud ~ gender + age + college + score + amount + declines, subset=train_set)
my_lda
pi_hat_lda = predict(my_lda)$posterior[,2]
pi_hat_lda
y_hat3 = as.numeric(pi_hat_lda > tau)
y_hat3
overall_accuracy_train3 = mean(fraud[train_set] == y_hat3)
overall_accuracy_train3
auc_lda_train = calc_auc(fraud[train_set], pi_hat_lda)
auc_lda_train
draw_roc(fraud[train_set], pi_hat_lda)
pi_hat_lda2 = predict(my_lda, newdata=cc_fraud[test_set,])$posterior[,2]
pi_hat_lda2
y_hat4 = as.numeric(pi_hat_lda2 > tau)
y_hat4
overall_accuracy_test4 = mean(fraud[test_set] == y_hat4)
overall_accuracy_test4
auc_lda_test = calc_auc(fraud[test_set], pi_hat_lda2)
auc_lda_test
draw_roc(fraud[test_set], pi_hat_lda2)
gm = gam(fraud ~ gender + s(age,4) + college + s(score,4) + s(amount,4) + s(declines,4), subset=train_set, binomial)
pi_hat_gam = predict(gm)
pi_hat_gam
y_hat5 = as.numeric(pi_hat_gam > tau)
y_hat5
overall_accuracy_train5 = mean(fraud[train_set] == y_hat5)
overall_accuracy_train5
auc_gam_train = calc_auc(fraud[train_set], pi_hat_gam)
auc_gam_train
draw_roc(fraud[train_set], pi_hat_gam)
pi_hat_gam2 = predict(gm, newdata=cc_fraud[test_set,])
pi_hat_gam2
y_hat6 = as.numeric(pi_hat_gam2 > tau)
y_hat6
overall_accuracy_test6 = mean(fraud[test_set] == y_hat6)
overall_accuracy_test6
auc_gam_test = calc_auc(fraud[test_set], pi_hat_gam2)
auc_gam_test
draw_roc(fraud[test_set], pi_hat_gam2)
fraud_f = factor(fraud)
tree_class = tree(fraud_f ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_tree = predict(tree_class)[,2]
y_hat7 = as.numeric(pi_hat_tree > tau)
y_hat7
overall_accuracy_train7 = mean(fraud[train_set] == y_hat7)
overall_accuracy_train7
auc_tree_train = calc_auc(fraud[train_set], pi_hat_tree)
auc_tree_train
draw_roc(fraud[train_set], pi_hat_tree)
pi_hat_tree2 = predict(tree_class, newdata=cc_fraud[test_set,])[,2]
y_hat8 = as.numeric(pi_hat_tree2 > tau)
y_hat8
overall_accuracy_test8 = mean(fraud[train_set] == y_hat8)
overall_accuracy_test8
auc_tree_test = calc_auc(fraud[test_set], pi_hat_tree2)
auc_tree_test
draw_roc(fraud[test_set], pi_hat_tree2)
set.seed(4350)
my_forest = randomForest(fraud_f ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_forest = predict(my_forest, type="prob")[,2]
y_hat9 = as.numeric(pi_hat_forest > tau)
y_hat9
overall_accuracy_train9 = mean(fraud[train_set] == y_hat9)
overall_accuracy_train9
auc_forest_train = calc_auc(fraud[train_set], pi_hat_forest)
auc_forest_train
draw_roc(fraud[train_set], pi_hat_forest)
pi_hat_forest2 = predict(my_forest, type="prob", newdata=cc_fraud[test_set,])[,2]
y_hat10 = as.numeric(pi_hat_forest2 > tau)
y_hat10
auc_forest_test = calc_auc(fraud[test_set], pi_hat_forest2)
auc_forest_test
overall_accuracy_test10 = mean(fraud[test_set] == y_hat10)
overall_accuracy_test10
draw_roc(fraud[test_set], pi_hat_forest2)
tau = .09
my_lda = lda(fraud ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_lda = predict(my_lda)$posterior[,2]
y_hat3 = as.numeric(pi_hat_lda > tau)
overall_accuracy_train3 = mean(fraud[train_set] == y_hat3)
auc_lda_train = calc_auc(fraud[train_set], pi_hat_lda)
draw_roc(fraud[train_set], pi_hat_lda)
##### Testing
pi_hat_lda2 = predict(my_lda, newdata=cc_fraud[test_set,])$posterior[,2]
y_hat4 = as.numeric(pi_hat_lda2 > tau)
overall_accuracy_test4 = mean(fraud[test_set] == y_hat4)
auc_lda_test = calc_auc(fraud[test_set], pi_hat_lda2)
draw_roc(fraud[test_set], pi_hat_lda2)
table(y_hat4, fraud[test_set])
overall_total = 1e99
for (i in seq(from = 0.5, to = 0, by = -0.01)) {
false_negative = 0
false_positive = 0
total = 0
my_lda = lda(fraud ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_lda_min = predict(my_lda, newdata=cc_fraud[test_set,])$posterior[,2]
y_hat = as.numeric(pi_hat_lda_min > i)
for (j in 1:length(test_set)) {
if (fraud[test_set][j] == 1 && y_hat[j] == 0) {
false_negative = false_negative + amount[test_set][j]
}
if (fraud[test_set][j] == 0 && y_hat[j] == 1) {
false_positive = false_positive + 25
}
total = total + false_negative + false_positive
}
if (total < overall_total) {
overall_total = total
print(i)
print(overall_total)
}
}
set.seed(4350)
n = nrow(cc_fraud)
n_train = ceiling(0.5*n)
n_train
n_test = n - n_train
n_test
train_set = sample(n,n_train,replace=FALSE)
train_set
test_set = seq_len(n)[-train_set]
test_set
tau = 0.50
slr_train = glm(fraud ~ gender + age + college + score + amount + declines, family = "binomial", data = cc_fraud, subset = train_set)
slr_train
pi_hat_logistic = predict(slr_train, type="response")
pi_hat_logistic
y_hat1 = as.numeric(pi_hat_logistic > tau)
y_hat1
overall_accuracy_train1 = mean(fraud[train_set] == y_hat1)
overall_accuracy_train1
auc_log_train = calc_auc(fraud[train_set], pi_hat_logistic)
auc_log_train
draw_roc(fraud[train_set], pi_hat_logistic)
pi_hat_logistic2 = predict(slr_train, type= "response", newdata=cc_fraud[test_set,])
pi_hat_logistic2
y_hat2 = as.numeric(pi_hat_logistic2 > tau)
y_hat2
overall_accuracy_test2 = mean(fraud[test_set] == y_hat2)
overall_accuracy_test2
auc_log_test = calc_auc(fraud[test_set], pi_hat_logistic2)
auc_log_test
draw_roc(fraud[test_set], pi_hat_logistic2)
draw_roc(fraud[test_set], pi_hat_logistic2)
my_lda = lda(fraud ~ gender + age + college + score + amount + declines, subset=train_set)
my_lda
pi_hat_lda = predict(my_lda)$posterior[,2]
pi_hat_lda
y_hat3 = as.numeric(pi_hat_lda > tau)
y_hat3
overall_accuracy_train3 = mean(fraud[train_set] == y_hat3)
overall_accuracy_train3
auc_lda_train = calc_auc(fraud[train_set], pi_hat_lda)
auc_lda_train
draw_roc(fraud[train_set], pi_hat_lda)
pi_hat_lda2 = predict(my_lda, newdata=cc_fraud[test_set,])$posterior[,2]
pi_hat_lda2
y_hat4 = as.numeric(pi_hat_lda2 > tau)
y_hat4
overall_accuracy_test4 = mean(fraud[test_set] == y_hat4)
overall_accuracy_test4
auc_lda_test = calc_auc(fraud[test_set], pi_hat_lda2)
auc_lda_test
draw_roc(fraud[test_set], pi_hat_lda2)
draw_roc(fraud[test_set], pi_hat_lda2)
gm = gam(fraud ~ gender + s(age,4) + college + s(score,4) + s(amount,4) + s(declines,4), subset=train_set, binomial)
pi_hat_gam = predict(gm)
pi_hat_gam
y_hat5 = as.numeric(pi_hat_gam > tau)
y_hat5
overall_accuracy_train5 = mean(fraud[train_set] == y_hat5)
overall_accuracy_train5
auc_gam_train = calc_auc(fraud[train_set], pi_hat_gam)
auc_gam_train
draw_roc(fraud[train_set], pi_hat_gam)
pi_hat_gam2 = predict(gm, newdata=cc_fraud[test_set,])
pi_hat_gam2
y_hat6 = as.numeric(pi_hat_gam2 > tau)
y_hat6
overall_accuracy_test6 = mean(fraud[test_set] == y_hat6)
overall_accuracy_test6
auc_gam_test = calc_auc(fraud[test_set], pi_hat_gam2)
auc_gam_test
draw_roc(fraud[test_set], pi_hat_gam2)
draw_roc(fraud[test_set], pi_hat_gam2)
fraud_f = factor(fraud)
tree_class = tree(fraud_f ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_tree = predict(tree_class)[,2]
y_hat7 = as.numeric(pi_hat_tree > tau)
y_hat7
overall_accuracy_train7 = mean(fraud[train_set] == y_hat7)
overall_accuracy_train7
auc_tree_train = calc_auc(fraud[train_set], pi_hat_tree)
auc_tree_train
draw_roc(fraud[train_set], pi_hat_tree)
pi_hat_tree2 = predict(tree_class, newdata=cc_fraud[test_set,])[,2]
y_hat8 = as.numeric(pi_hat_tree2 > tau)
y_hat8
overall_accuracy_test8 = mean(fraud[train_set] == y_hat8)
overall_accuracy_test8
auc_tree_test = calc_auc(fraud[test_set], pi_hat_tree2)
auc_tree_test
draw_roc(fraud[test_set], pi_hat_tree2)
set.seed(4350)
my_forest = randomForest(fraud_f ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_forest = predict(my_forest, type="prob")[,2]
y_hat9 = as.numeric(pi_hat_forest > tau)
y_hat9
overall_accuracy_train9 = mean(fraud[train_set] == y_hat9)
overall_accuracy_train9
auc_forest_train = calc_auc(fraud[train_set], pi_hat_forest)
auc_forest_train
draw_roc(fraud[train_set], pi_hat_forest)
pi_hat_forest2 = predict(my_forest, type="prob", newdata=cc_fraud[test_set,])[,2]
y_hat10 = as.numeric(pi_hat_forest2 > tau)
y_hat10
auc_forest_test = calc_auc(fraud[test_set], pi_hat_forest2)
auc_forest_test
overall_accuracy_test10 = mean(fraud[test_set] == y_hat10)
overall_accuracy_test10
draw_roc(fraud[test_set], pi_hat_forest2)
# Sampling
?sample_n()
setwd("~/Desktop/UCSD_Classwork/R_Analysis/01_Demo")
# Sampling
library(dplyr)
?sample_n()
# Practice generting random samples
population_table <- read.csv('used_car_data.csv',check.names = F,stringsAsFactors = F) #import used car dataset
plt <- ggplot(population_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
library(ggplot2)
plt <- ggplot(population_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
?t.test()
# If we want to test if the miles driven from our previous sample dataset is
# statistically different from the miles driven in our population data
t.test(log10(sample_table$Miles_Driven),mu=mean(log10(population_table$Miles_Driven))) #compare sample versus population means
# Let's test whether the mean miles driven of two samples from our used car
# dataset are statistically different.
sample_table <- population_table %>% sample_n(50) #generate 50 randomly sampled data points
sample_table2 <- population_table %>% sample_n(50) #generate another 50 randomly sampled data points
# Since our samples should not contain bias, we expect to fail to reject the null hypothesis
t.test(log10(sample_table$Miles_Driven),log10(sample_table2$Miles_Driven)) #compare means of two samples
?t.test()
# Generate two samples
mpg_data <- read.csv('mpg_modified.csv') #import dataset
mpg_1999 <- mpg_data %>% filter(year==1999) #select only data points where the year is 1999
mpg_2008 <- mpg_data %>% filter(year==2008) #select only data points where the year is 2008
t.test(mpg_1999$hwy,mpg_2008$hwy,paired = T) #compare the mean difference between two samples
?aov()
mtcars
# "Is there any statistical difference in the horsepower of a vehicle based on its engine type?"
mtcars_filt <- mtcars[,c("hp","cyl")] #filter columns from mtcars dataset
mtcars_filt$cyl <- factor(mtcars_filt$cyl) #convert numeric column to factor
aov(hp ~ cyl,data=mtcars_filt) #compare means across multiple levels
# to find p-value
summary(aov(hp ~ cyl,data=mtcars_filt))
?cor()
head(mtcars)
# we'll test whether or not horsepower (hp) is correlated with quarter-mile race time (qsec).
plt <- ggplot(mtcars,aes(x=hp,y=qsec)) #import dataset into ggplot2
plt + geom_point() #create scatter plot
cor(mtcars$hp,mtcars$qsec) #calculate correlation coefficient
# Use our usedcars dataset
used_cars <- read.csv('used_car_data.csv',stringsAsFactors = F) #read in dataset
head(used_cars)
# we'll test whether or not vehicle miles driven and selling price are correlated
plt <- ggplot(used_cars,aes(x=Miles_Driven,y=Selling_Price)) #import dataset into ggplot2
plt + geom_point() #create a scatter plot
cor(used_cars$Miles_Driven,used_cars$Selling_Price) #calculate correlation coefficient
# Making a correlation matrix
used_matrix <- as.matrix(used_cars[,c("Selling_Price","Present_Price","Miles_Driven")]) #convert data frame into numeric matrix
cor(used_matrix)
?lm()
# Using our simple linear regression model, we'll test whether or not
# quarter-mile race time (qsec) can be predicted using a linear model and horsepower (hp).
lm(qsec ~ hp,mtcars) #create linear model
summary(lm(qsec~hp,mtcars)) #summarize linear model
# we can visualize the fitted line against our dataset using ggplot2.
model <- lm(qsec ~ hp,mtcars) #create linear model
yvals <- model$coefficients['hp']*mtcars$hp + model$coefficients['(Intercept)'] #determine y-axis values from linear model
plt <- ggplot(mtcars,aes(x=hp,y=qsec)) #import dataset into ggplot2
plt + geom_point() + geom_line(aes(y=yvals), color = "red") #plot scatter and linear model
# To better predict the quarter-mile time (qsec) dependent variable, we can add
# other variables of interest such as fuel efficiency (mpg), engine size (disp),
# rear axle ratio (drat), vehicle weight (wt), and horsepower (hp) as independent
# variables to our multiple linear regression model.
lm(qsec ~ mpg + disp + drat + wt + hp,data=mtcars) #generate multiple linear regression model
summary(lm(qsec ~ mpg + disp + drat + wt + hp,data=mtcars)) #generate summary statistics
?chisq.test()
?chisq.test()
# If we want to test whether there is a statistical difference in the distributions
# of vehicle class across 1999 and 2008 from our mpg dataset, we would first need
# to build our contingency table as follows
table(mpg$class,mpg$year) #generate contingency table
# If we want to test whether there is a statistical difference in the distributions
# of vehicle class across 1999 and 2008 from our mpg dataset, we would first need
# to build our contingency table as follows and then test it
tbl <- table(mpg$class,mpg$year) #generate contingency table
chisq.test(tbl) #compare categorical distributions
setwd("~/Desktop/UCSD_Classwork/MechaCar_Statistical_Analysis/R_Analysis/01_Demo")
