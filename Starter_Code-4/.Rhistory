fpr[i] <- mean(ph[y==0] > taus[i])
}
sens <- c(1,sens)
fpr <- c(1,fpr)
# if new==TRUE, draw a new plot:
if (new) {
plot(NA,NA,type="n",xlim=c(0,1),ylim=c(0,1),
xlab="False Positive Rate",
ylab="Sensitivity")
abline(h=c(0,1),v=c(0,1),a=0,b=1)
}
lines(fpr,sens,lwd=2,col=clr)
}
summary(age)
summary(score)
summary(amount)
summary(declines)
table(fraud)
table(gender)
table(college)
boxplot(age, main = "Age of credit card users", ylab = "Age (years)")
boxplot(score, main = "Credit score of credit card users", ylab = "Credit score")
boxplot(amount, main = "Average amount of last 5 attempted charges", ylab = "Amount (US Dollars")
boxplot(declines, main = "Number of declines in last 5 attempted charges", ylab = "Number of declines")
boxplot(score ~ fraud, main = "Credit score and fraud detection", ylab = "Credit Score", xlab = "Fraud detected")
hist(age, main = "Age of credit card users")
hist(score, main = "Credit Score of credit card users")
hist(amount, main = "Average amount of last 5 attenpted charges")
hist(declines, main = "Number of declines in last 5 attempted charges")
set.seed(4350)
n = nrow(cc_fraud)
n_train = ceiling(0.5*n)
n_train
n_test = n - n_train
n_test
train_set = sample(n,n_train,replace=FALSE)
train_set
test_set = seq_len(n)[-train_set]
test_set
tau = 0.50
slr_train = glm(fraud ~ gender + age + college + score + amount + declines, family = "binomial", data = cc_fraud, subset = train_set)
slr_train
pi_hat_logistic = predict(slr_train, type="response")
pi_hat_logistic
y_hat1 = as.numeric(pi_hat_logistic > tau)
y_hat1
overall_accuracy_train1 = mean(fraud[train_set] == y_hat1)
overall_accuracy_train1
auc_log_train = calc_auc(fraud[train_set], pi_hat_logistic)
auc_log_train
draw_roc(fraud[train_set], pi_hat_logistic)
pi_hat_logistic2 = predict(slr_train, type= "response", newdata=cc_fraud[test_set,])
pi_hat_logistic2
y_hat2 = as.numeric(pi_hat_logistic2 > tau)
y_hat2
overall_accuracy_test2 = mean(fraud[test_set] == y_hat2)
overall_accuracy_test2
auc_log_test = calc_auc(fraud[test_set], pi_hat_logistic2)
auc_log_test
draw_roc(fraud[test_set], pi_hat_logistic2)
my_lda = lda(fraud ~ gender + age + college + score + amount + declines, subset=train_set)
my_lda
pi_hat_lda = predict(my_lda)$posterior[,2]
pi_hat_lda
y_hat3 = as.numeric(pi_hat_lda > tau)
y_hat3
overall_accuracy_train3 = mean(fraud[train_set] == y_hat3)
overall_accuracy_train3
auc_lda_train = calc_auc(fraud[train_set], pi_hat_lda)
auc_lda_train
draw_roc(fraud[train_set], pi_hat_lda)
pi_hat_lda2 = predict(my_lda, newdata=cc_fraud[test_set,])$posterior[,2]
pi_hat_lda2
y_hat4 = as.numeric(pi_hat_lda2 > tau)
y_hat4
overall_accuracy_test4 = mean(fraud[test_set] == y_hat4)
overall_accuracy_test4
auc_lda_test = calc_auc(fraud[test_set], pi_hat_lda2)
auc_lda_test
draw_roc(fraud[test_set], pi_hat_lda2)
gm = gam(fraud ~ gender + s(age,4) + college + s(score,4) + s(amount,4) + s(declines,4), subset=train_set, binomial)
pi_hat_gam = predict(gm)
pi_hat_gam
y_hat5 = as.numeric(pi_hat_gam > tau)
y_hat5
overall_accuracy_train5 = mean(fraud[train_set] == y_hat5)
overall_accuracy_train5
auc_gam_train = calc_auc(fraud[train_set], pi_hat_gam)
auc_gam_train
draw_roc(fraud[train_set], pi_hat_gam)
pi_hat_gam2 = predict(gm, newdata=cc_fraud[test_set,])
pi_hat_gam2
y_hat6 = as.numeric(pi_hat_gam2 > tau)
y_hat6
overall_accuracy_test6 = mean(fraud[test_set] == y_hat6)
overall_accuracy_test6
auc_gam_test = calc_auc(fraud[test_set], pi_hat_gam2)
auc_gam_test
draw_roc(fraud[test_set], pi_hat_gam2)
fraud_f = factor(fraud)
tree_class = tree(fraud_f ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_tree = predict(tree_class)[,2]
y_hat7 = as.numeric(pi_hat_tree > tau)
y_hat7
overall_accuracy_train7 = mean(fraud[train_set] == y_hat7)
overall_accuracy_train7
auc_tree_train = calc_auc(fraud[train_set], pi_hat_tree)
auc_tree_train
draw_roc(fraud[train_set], pi_hat_tree)
pi_hat_tree2 = predict(tree_class, newdata=cc_fraud[test_set,])[,2]
y_hat8 = as.numeric(pi_hat_tree2 > tau)
y_hat8
overall_accuracy_test8 = mean(fraud[train_set] == y_hat8)
overall_accuracy_test8
auc_tree_test = calc_auc(fraud[test_set], pi_hat_tree2)
auc_tree_test
draw_roc(fraud[test_set], pi_hat_tree2)
set.seed(4350)
my_forest = randomForest(fraud_f ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_forest = predict(my_forest, type="prob")[,2]
y_hat9 = as.numeric(pi_hat_forest > tau)
y_hat9
overall_accuracy_train9 = mean(fraud[train_set] == y_hat9)
overall_accuracy_train9
auc_forest_train = calc_auc(fraud[train_set], pi_hat_forest)
auc_forest_train
draw_roc(fraud[train_set], pi_hat_forest)
pi_hat_forest2 = predict(my_forest, type="prob", newdata=cc_fraud[test_set,])[,2]
y_hat10 = as.numeric(pi_hat_forest2 > tau)
y_hat10
auc_forest_test = calc_auc(fraud[test_set], pi_hat_forest2)
auc_forest_test
overall_accuracy_test10 = mean(fraud[test_set] == y_hat10)
overall_accuracy_test10
draw_roc(fraud[test_set], pi_hat_forest2)
tau = .09
my_lda = lda(fraud ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_lda = predict(my_lda)$posterior[,2]
y_hat3 = as.numeric(pi_hat_lda > tau)
overall_accuracy_train3 = mean(fraud[train_set] == y_hat3)
auc_lda_train = calc_auc(fraud[train_set], pi_hat_lda)
draw_roc(fraud[train_set], pi_hat_lda)
##### Testing
pi_hat_lda2 = predict(my_lda, newdata=cc_fraud[test_set,])$posterior[,2]
y_hat4 = as.numeric(pi_hat_lda2 > tau)
overall_accuracy_test4 = mean(fraud[test_set] == y_hat4)
auc_lda_test = calc_auc(fraud[test_set], pi_hat_lda2)
draw_roc(fraud[test_set], pi_hat_lda2)
table(y_hat4, fraud[test_set])
overall_total = 1e99
for (i in seq(from = 0.5, to = 0, by = -0.01)) {
false_negative = 0
false_positive = 0
total = 0
my_lda = lda(fraud ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_lda_min = predict(my_lda, newdata=cc_fraud[test_set,])$posterior[,2]
y_hat = as.numeric(pi_hat_lda_min > i)
for (j in 1:length(test_set)) {
if (fraud[test_set][j] == 1 && y_hat[j] == 0) {
false_negative = false_negative + amount[test_set][j]
}
if (fraud[test_set][j] == 0 && y_hat[j] == 1) {
false_positive = false_positive + 25
}
total = total + false_negative + false_positive
}
if (total < overall_total) {
overall_total = total
print(i)
print(overall_total)
}
}
set.seed(4350)
n = nrow(cc_fraud)
n_train = ceiling(0.5*n)
n_train
n_test = n - n_train
n_test
train_set = sample(n,n_train,replace=FALSE)
train_set
test_set = seq_len(n)[-train_set]
test_set
tau = 0.50
slr_train = glm(fraud ~ gender + age + college + score + amount + declines, family = "binomial", data = cc_fraud, subset = train_set)
slr_train
pi_hat_logistic = predict(slr_train, type="response")
pi_hat_logistic
y_hat1 = as.numeric(pi_hat_logistic > tau)
y_hat1
overall_accuracy_train1 = mean(fraud[train_set] == y_hat1)
overall_accuracy_train1
auc_log_train = calc_auc(fraud[train_set], pi_hat_logistic)
auc_log_train
draw_roc(fraud[train_set], pi_hat_logistic)
pi_hat_logistic2 = predict(slr_train, type= "response", newdata=cc_fraud[test_set,])
pi_hat_logistic2
y_hat2 = as.numeric(pi_hat_logistic2 > tau)
y_hat2
overall_accuracy_test2 = mean(fraud[test_set] == y_hat2)
overall_accuracy_test2
auc_log_test = calc_auc(fraud[test_set], pi_hat_logistic2)
auc_log_test
draw_roc(fraud[test_set], pi_hat_logistic2)
draw_roc(fraud[test_set], pi_hat_logistic2)
my_lda = lda(fraud ~ gender + age + college + score + amount + declines, subset=train_set)
my_lda
pi_hat_lda = predict(my_lda)$posterior[,2]
pi_hat_lda
y_hat3 = as.numeric(pi_hat_lda > tau)
y_hat3
overall_accuracy_train3 = mean(fraud[train_set] == y_hat3)
overall_accuracy_train3
auc_lda_train = calc_auc(fraud[train_set], pi_hat_lda)
auc_lda_train
draw_roc(fraud[train_set], pi_hat_lda)
pi_hat_lda2 = predict(my_lda, newdata=cc_fraud[test_set,])$posterior[,2]
pi_hat_lda2
y_hat4 = as.numeric(pi_hat_lda2 > tau)
y_hat4
overall_accuracy_test4 = mean(fraud[test_set] == y_hat4)
overall_accuracy_test4
auc_lda_test = calc_auc(fraud[test_set], pi_hat_lda2)
auc_lda_test
draw_roc(fraud[test_set], pi_hat_lda2)
draw_roc(fraud[test_set], pi_hat_lda2)
gm = gam(fraud ~ gender + s(age,4) + college + s(score,4) + s(amount,4) + s(declines,4), subset=train_set, binomial)
pi_hat_gam = predict(gm)
pi_hat_gam
y_hat5 = as.numeric(pi_hat_gam > tau)
y_hat5
overall_accuracy_train5 = mean(fraud[train_set] == y_hat5)
overall_accuracy_train5
auc_gam_train = calc_auc(fraud[train_set], pi_hat_gam)
auc_gam_train
draw_roc(fraud[train_set], pi_hat_gam)
pi_hat_gam2 = predict(gm, newdata=cc_fraud[test_set,])
pi_hat_gam2
y_hat6 = as.numeric(pi_hat_gam2 > tau)
y_hat6
overall_accuracy_test6 = mean(fraud[test_set] == y_hat6)
overall_accuracy_test6
auc_gam_test = calc_auc(fraud[test_set], pi_hat_gam2)
auc_gam_test
draw_roc(fraud[test_set], pi_hat_gam2)
draw_roc(fraud[test_set], pi_hat_gam2)
fraud_f = factor(fraud)
tree_class = tree(fraud_f ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_tree = predict(tree_class)[,2]
y_hat7 = as.numeric(pi_hat_tree > tau)
y_hat7
overall_accuracy_train7 = mean(fraud[train_set] == y_hat7)
overall_accuracy_train7
auc_tree_train = calc_auc(fraud[train_set], pi_hat_tree)
auc_tree_train
draw_roc(fraud[train_set], pi_hat_tree)
pi_hat_tree2 = predict(tree_class, newdata=cc_fraud[test_set,])[,2]
y_hat8 = as.numeric(pi_hat_tree2 > tau)
y_hat8
overall_accuracy_test8 = mean(fraud[train_set] == y_hat8)
overall_accuracy_test8
auc_tree_test = calc_auc(fraud[test_set], pi_hat_tree2)
auc_tree_test
draw_roc(fraud[test_set], pi_hat_tree2)
set.seed(4350)
my_forest = randomForest(fraud_f ~ gender + age + college + score + amount + declines, subset=train_set)
pi_hat_forest = predict(my_forest, type="prob")[,2]
y_hat9 = as.numeric(pi_hat_forest > tau)
y_hat9
overall_accuracy_train9 = mean(fraud[train_set] == y_hat9)
overall_accuracy_train9
auc_forest_train = calc_auc(fraud[train_set], pi_hat_forest)
auc_forest_train
draw_roc(fraud[train_set], pi_hat_forest)
pi_hat_forest2 = predict(my_forest, type="prob", newdata=cc_fraud[test_set,])[,2]
y_hat10 = as.numeric(pi_hat_forest2 > tau)
y_hat10
auc_forest_test = calc_auc(fraud[test_set], pi_hat_forest2)
auc_forest_test
overall_accuracy_test10 = mean(fraud[test_set] == y_hat10)
overall_accuracy_test10
draw_roc(fraud[test_set], pi_hat_forest2)
# Sampling
?sample_n()
setwd("~/Desktop/UCSD_Classwork/R_Analysis/01_Demo")
# Sampling
library(dplyr)
?sample_n()
# Practice generting random samples
population_table <- read.csv('used_car_data.csv',check.names = F,stringsAsFactors = F) #import used car dataset
plt <- ggplot(population_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
library(ggplot2)
plt <- ggplot(population_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
?t.test()
# If we want to test if the miles driven from our previous sample dataset is
# statistically different from the miles driven in our population data
t.test(log10(sample_table$Miles_Driven),mu=mean(log10(population_table$Miles_Driven))) #compare sample versus population means
# Let's test whether the mean miles driven of two samples from our used car
# dataset are statistically different.
sample_table <- population_table %>% sample_n(50) #generate 50 randomly sampled data points
sample_table2 <- population_table %>% sample_n(50) #generate another 50 randomly sampled data points
# Since our samples should not contain bias, we expect to fail to reject the null hypothesis
t.test(log10(sample_table$Miles_Driven),log10(sample_table2$Miles_Driven)) #compare means of two samples
?t.test()
# Generate two samples
mpg_data <- read.csv('mpg_modified.csv') #import dataset
mpg_1999 <- mpg_data %>% filter(year==1999) #select only data points where the year is 1999
mpg_2008 <- mpg_data %>% filter(year==2008) #select only data points where the year is 2008
t.test(mpg_1999$hwy,mpg_2008$hwy,paired = T) #compare the mean difference between two samples
?aov()
mtcars
# "Is there any statistical difference in the horsepower of a vehicle based on its engine type?"
mtcars_filt <- mtcars[,c("hp","cyl")] #filter columns from mtcars dataset
mtcars_filt$cyl <- factor(mtcars_filt$cyl) #convert numeric column to factor
aov(hp ~ cyl,data=mtcars_filt) #compare means across multiple levels
# to find p-value
summary(aov(hp ~ cyl,data=mtcars_filt))
?cor()
head(mtcars)
# we'll test whether or not horsepower (hp) is correlated with quarter-mile race time (qsec).
plt <- ggplot(mtcars,aes(x=hp,y=qsec)) #import dataset into ggplot2
plt + geom_point() #create scatter plot
cor(mtcars$hp,mtcars$qsec) #calculate correlation coefficient
# Use our usedcars dataset
used_cars <- read.csv('used_car_data.csv',stringsAsFactors = F) #read in dataset
head(used_cars)
# we'll test whether or not vehicle miles driven and selling price are correlated
plt <- ggplot(used_cars,aes(x=Miles_Driven,y=Selling_Price)) #import dataset into ggplot2
plt + geom_point() #create a scatter plot
cor(used_cars$Miles_Driven,used_cars$Selling_Price) #calculate correlation coefficient
# Making a correlation matrix
used_matrix <- as.matrix(used_cars[,c("Selling_Price","Present_Price","Miles_Driven")]) #convert data frame into numeric matrix
cor(used_matrix)
?lm()
# Using our simple linear regression model, we'll test whether or not
# quarter-mile race time (qsec) can be predicted using a linear model and horsepower (hp).
lm(qsec ~ hp,mtcars) #create linear model
summary(lm(qsec~hp,mtcars)) #summarize linear model
# we can visualize the fitted line against our dataset using ggplot2.
model <- lm(qsec ~ hp,mtcars) #create linear model
yvals <- model$coefficients['hp']*mtcars$hp + model$coefficients['(Intercept)'] #determine y-axis values from linear model
plt <- ggplot(mtcars,aes(x=hp,y=qsec)) #import dataset into ggplot2
plt + geom_point() + geom_line(aes(y=yvals), color = "red") #plot scatter and linear model
# To better predict the quarter-mile time (qsec) dependent variable, we can add
# other variables of interest such as fuel efficiency (mpg), engine size (disp),
# rear axle ratio (drat), vehicle weight (wt), and horsepower (hp) as independent
# variables to our multiple linear regression model.
lm(qsec ~ mpg + disp + drat + wt + hp,data=mtcars) #generate multiple linear regression model
summary(lm(qsec ~ mpg + disp + drat + wt + hp,data=mtcars)) #generate summary statistics
?chisq.test()
?chisq.test()
# If we want to test whether there is a statistical difference in the distributions
# of vehicle class across 1999 and 2008 from our mpg dataset, we would first need
# to build our contingency table as follows
table(mpg$class,mpg$year) #generate contingency table
# If we want to test whether there is a statistical difference in the distributions
# of vehicle class across 1999 and 2008 from our mpg dataset, we would first need
# to build our contingency table as follows and then test it
tbl <- table(mpg$class,mpg$year) #generate contingency table
chisq.test(tbl) #compare categorical distributions
setwd("~/Desktop/UCSD_Classwork/MechaCar_Statistical_Analysis/R_Analysis/01_Demo")
setwd("~/Desktop/UCSD_Classwork/MechaCar_Statistical_Analysis/Starter_Code-4")
library(dplyr)
# let's read in our CSV file
df <- read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
df
library(dplyr)
# let's read in our CSV file
df <- read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
df
View(df)
lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=df)
summary(lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=df))
# To test the distribution of vehicle weights from the built-in mtcars dataset
ggplot(mtcars,aes(x=wt)) + geom_density() #visualize distribution using density plot
# Qualitative test for normality
# The qualitative test for normality is a visual assessment of the distribution
# of data, which looks for the characteristic bell curve shape across the distribution.
library(ggplot2)
# To test the distribution of vehicle weights from the built-in mtcars dataset
ggplot(mtcars,aes(x=wt)) + geom_density() #visualize distribution using density plot
# To better predict the quarter-mile time (qsec) dependent variable, we can add
# other variables of interest such as fuel efficiency (mpg), engine size (disp),
# rear axle ratio (drat), vehicle weight (wt), and horsepower (hp) as independent
# variables to our multiple linear regression model.
lm(qsec ~ mpg + disp + drat + wt + hp,data=mtcars) #generate multiple linear regression model
summary(lm(qsec ~ mpg + disp + drat + wt + hp,data=mtcars)) #generate summary statistics
library(dplyr)
# let's read in our CSV file and create a table
df <- read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=df)
summary(lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=df))
# p-value = 5.35e-11
# r^2 =
# Part 1
library(dplyr)
# let's read in our CSV file and create a table
MechaCar_mpg <- read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=MechaCar_mpg)
summary(lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=MechaCar_mpg))
# p-value = 5.35e-11
# r^2 = 0.7149
View(MechaCar_mpg)
View(MechaCar_mpg)
# let's read in our CSV file and create a table
Suspension_Coil = read.csv(file="Suspension_Coil.csv", check_names=F, stringsAsFactors=F)
# let's read in our CSV file and create a table
Suspension_Coil = read.csv(file="Suspension_Coil.csv", check.names=F, stringsAsFactors=F)
View(Suspension_Coil)
# Part 1
library(dplyr)
# let's read in our CSV file and create a table
MechaCar_mpg = read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=MechaCar_mpg)
summary(lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=MechaCar_mpg))
# p-value = 5.35e-11
# r^2 = 0.7149
# Part 2
# let's read in our CSV file and create a table
Suspension_Coil = read.csv(file="Suspension_Coil.csv", check.names=F, stringsAsFactors=F)
total_summary = summarize(Mean=mean(PSI), Medium=median(PSI), Variance=var(PSI), SD=sd(PSI), .groups = 'keep')
total_summary = Suspension_Coil %>% summarize(Mean=mean(PSI), Medium=median(PSI), Variance=var(PSI), SD=sd(PSI), .groups = 'keep')
View(total_summary)
lot_summary = Suspension_Coil %>% group_by(Manufacturing_Lot) %>% summarize(Mean=mean(PSI), Medium=median(PSI), Variance=var(PSI), SD=sd(PSI), .groups = 'keep')
View(lot_summary)
t.test(Suspension_Coil$PSI, mu=1500)
View(Suspension_Coil)
View(total_summary)
# Part 3
?t.test
t.test(subset(Suspension_Coil$PSI, Suspension_Coil$Manufacturing_Lot == "Lot1"), mu=1500)
t.test(Suspension_Coil$PSI, mu=1500, subset(Suspension_Coil$Manufacturing_Lot == "Lot1"))
t.test(subset(Suspension_Coil, Manufacturing_Lot == "Lot1"), mu=1500)
t.test(subset(Suspension_Coil, Manufacturing_Lot == "Lot1"))
t.test(Suspension_Coil$PSI, mu=1500, subset(Suspension_Coil, Manufacturing_Lot == "Lot1"))
# Part 3
?t.test
t.test(Suspension_Coil$PSI ~ 1, subset(Suspension_Coil, Manufacturing_Lot == "Lot1"))
t.test(Suspension_Coil$PSI ~ 1, subset(Suspension_Coil, Manufacturing_Lot == "Lot1"), mu=1500)
t.test(Suspension_Coil$PSI, mu=1500)
t.test(Suspension_Coil$PSI ~ 1, subset(Suspension_Coil, Manufacturing_Lot == "Lot2"), mu=1500)
t.test(Suspension_Coil$PSI ~ 1, subset(Suspension_Coil, Manufacturing_Lot == "Lot3"), mu=1500)
t.test(Suspension_Coil$PSI ~ Suspension_Coil$Manufacturing_Lot, subset(Suspension_Coil, Manufacturing_Lot == "Lot3"), mu=1500)
t.test(Suspension_Coil$PSI ~ Suspension_Coil$Manufacturing_Lot, data = Suspension_Coil, subset(Suspension_Coil, Manufacturing_Lot == "Lot3"), mu=1500)
t.test(Suspension_Coil$PSI ~ 1, subset(Suspension_Coil, Manufacturing_Lot == "Lot1"), mu=1500)
t.test(Suspension_Coil$PSI ~ 2, subset(Suspension_Coil, Manufacturing_Lot == "Lot2"), mu=1500)
View(lot_summary)
t.test(PSI ~ Manufacturing_Lot, data=Suspension_Coil, subset(Suspension_Coil, Manufacturing_Lot == "Lot2") , mu=1500)
# Part 1
library(dplyr)
# let's read in our CSV file and create a table
MechaCar_mpg = read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
# Design a linear model that predicts the mpg of MechaCar prototypes using every other variable
lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=MechaCar_mpg)
summary(lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=MechaCar_mpg))
# p-value = 5.35e-11
# r^2 = 0.7149
# Part 2
# let's read in our CSV file and create a table
Suspension_Coil = read.csv(file="Suspension_Coil.csv", check.names=F, stringsAsFactors=F)
# Get the mean, median, variance, and standard deviation of the suspension coil’s PSI column
total_summary = Suspension_Coil %>% summarize(Mean=mean(PSI), Medium=median(PSI), Variance=var(PSI), SD=sd(PSI), .groups = 'keep')
# Group each manufacturing lot by the mean, median, variance, and standard deviation of the suspension coil’s PSI column
lot_summary = Suspension_Coil %>% group_by(Manufacturing_Lot) %>% summarize(Mean=mean(PSI), Medium=median(PSI), Variance=var(PSI), SD=sd(PSI), .groups = 'keep')
# Part 3
?t.test
t.test(Suspension_Coil$PSI, mu=1500)
#t.test(Suspension_Coil$PSI ~ 1, subset(Suspension_Coil, Manufacturing_Lot == "Lot1"), mu=1500)
#t.test(Suspension_Coil$PSI ~ 1, subset(Suspension_Coil, Manufacturing_Lot == "Lot2"), mu=1500)
#t.test(Suspension_Coil$PSI ~ 1, subset(Suspension_Coil, Manufacturing_Lot == "Lot3"), mu=1500)
#t.test(Suspension_Coil$PSI ~ 1, subset(Suspension_Coil, Manufacturing_Lot == "Lot1"), mu=1500)
subset1 = subset(Suspension_Coil, Manufacturing_Lot == "Lot1")
View(subset1)
t.test(subset1$PSI, mu=1500)
subset2 = subset(Suspension_Coil, Manufacturing_Lot == "Lot2")
t.test(subset2$PSI, mu=1500)
subset3 = subset(Suspension_Coil, Manufacturing_Lot == "Lot3")
t.test(subset3$PSI, mu=1500)
# Comparing all Manufacturing Lots
t.test(Suspension_Coil$PSI, mu=1500)
subset1 = subset(Suspension_Coil, Manufacturing_Lot == "Lot1")
t.test(subset1$PSI, mu=1500)
subset2 = subset(Suspension_Coil, Manufacturing_Lot == "Lot2")
t.test(subset2$PSI, mu=1500)
subset3 = subset(Suspension_Coil, Manufacturing_Lot == "Lot3")
t.test(subset3$PSI, mu=1500)
View(subset3)
# Design a linear model that predicts the mpg of MechaCar prototypes using every other variable
lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=MechaCar_mpg)
summary(lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=MechaCar_mpg))
# p-value = 5.35e-11
View(MechaCar_mpg)
View(total_summary)
View(lot_summary)
# Part 3
?t.test
View(MechaCar_mpg)
